# HW1
It's the first homework of Natural Language Processing course in Spring 2024 at Sharif University of Technology. It's about preprocessing and doing some NLP tasks on a dataset.

In this project, each of us processed specific Persian or English data obtained through crawling or by using pre-existing datasets. Depending on the characteristics and type of dataset, as well as the target processing task, we first performed appropriate preprocessing steps and then carried out a processing task on the data.

Here is the directory guide:
- The processing related to the Persian data crawled from the [Zoomit](https://www.zoomit.ir/) website, along with the crawling script, can be found in the `Zoomit - KeyPhrase Extraction` directory. This work on the articles of Zoomit was conducted by [Ilia Hashemi Rad](https://github.com/IliaHashemiRad).
- The processing related to the Persian data ..., can be found in the `Poem - KeyPhrase Extraction` directory. This work on the poems of Khayyam and Ferdowsi was conducted by [Amir Mohammad Fakhimi](https://github.com/AmirMohammadFakhimi).

